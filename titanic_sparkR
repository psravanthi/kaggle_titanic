setwd("G:/Titanic")
Sys.setenv(SPARK_HOME = "C:/Users/sravanthi/Downloads/spark/spark-1.6.0-bin-hadoop2.6")
.libPaths(c(file.path(Sys.getenv("SPARK_HOME"), "R", "lib"), .libPaths()))

setwd("G:/Titanic")
# missForest package used for missing value imputation using random forests
# Caret package used for model building (model implementation, cross validation)
install.packages("missForest")
install.packages("caret")
library("missForest")
library("caret")
library("SparkR")
train<- read.csv("G:/Marketing Analytics/train.csv", stringsAsFactors =FALSE,na.strings =c(" ",NA,""))
test <- read.csv("test_titanic.csv", stringsAsFactors =FALSE,na.strings =c(" ",NA,""))
test$Survived <- -1

#Combining train and test
combined <- rbind(train,test)
combined$Fare <- ifelse(combined$Fare==0,NA,combined$Fare)

# Extracting title from names and grouping similar titles
combined$title <- sapply(combined$Name, FUN  = function(x) {strsplit(x,split='[,.]')[[1]][2]})
combined$title <- sub(' ','',combined$title)
combined$title[combined$title %in% c('Mme','Mlle')] <- 'Mlle'
combined$title[combined$title %in% c('Dona', 'Lady', 'the Countess')] <- 'Lady'
combined$title[combined$title %in% c('Capt', 'Don', 'Major', 'Sir','Jonkheer','Col')] <- 'Sir'
combined$title <- factor(combined$title)

#Converting variables to factors
combined$Sex <- as.factor(combined$Sex)
combined$Embarked <- as.factor(combined$Embarked)
combined$title <- as.factor(combined$title)

combined$familysize <- combined$SibSp+combined$Parch+1

# Calculating fare per passenger from the grouped ticket prices
tickets <- table(combined$Ticket)
ticketfreq <-  as.data.frame(tickets)
colnames(ticketfreq) <- c("Ticket","NumP")

# Initializing SparkR enviroment in stand alone mode 
sc <- sparkR.init(master = "local[*]")
sqlContext <- sparkRSQL.init(sc)
combinedRDD <- createDataFrame(sqlContext, combined)
ticketfreqRDD <- createDataFrame(sqlContext, ticketfreq)
registerTempTable(combinedRDD, "combinedtab")
registerTempTable(ticketfreqRDD, "ticketfreqtab")

# Using Spark SQL to calculate fare per passenger
combinedFreqRDD <- sql(sqlContext, "select c.*,t.NumP  from combinedtab c, ticketfreqtab t where c.Ticket=t.Ticket")
combinedFreqLocal <- collect(combinedFreqRDD)
combined$FarePerPgr <- combined$Fare/combined$NumP
combined <- combined[order(combined$PassengerId),]

#Removing irrelevant columns
combined_missing <- combined[,-which(names(combined) %in% c("Ticket","Name","SibSp","Parch","Fare","Cabin","NumP"))]

# Multiple imputation using random forests
combined_final <- missForest(combined_missing,ntree=100,verbose=TRUE)
combined_impute <- combined_final$ximp

# Splitting train and test sets
trainf<- combined_impute[combined_impute$Survived != -1,]
trainf$Survived <- as.factor(trainf$Survived)
testf <- combined_impute[combined_impute$Survived==-1,]
testf$Survived <- NULL

# Model building using glm
model <- glm(Survived ~ ., data = trainf, family = "binomial")

# Predicting on test data using glm
test_glm <- as.data.frame(predict(model,testf[,-which(names(testf) %in% c("Ticket","Name","SibSp","Parch","Fare","Cabin","NumP"))]))
test_glm <- cbind(test$PassengerId,test_glm)
colnames(test_glm) <- c("PassengerId","Survived")
write.csv(test_glm,"titanic_glm_model.csv",row.names=FALSE)

sparkR.stop()


